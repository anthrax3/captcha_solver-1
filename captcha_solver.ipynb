{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import imageio\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_path = './src_captchas/'\n",
    "whole_captchas_path = './processed_captchas/whole_captchas/'\n",
    "chars_path = './processed_captchas/chars/'\n",
    "filetype = '*.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captcha Solving using a CNN\n",
    "![](./src_captchas/HvJC56.jpg)\n",
    "Writing / using a CNN is probably overkill esp. for a captcha like this\n",
    "\n",
    "### Motivation\n",
    "* [Slacknotes](https://slacknotes.com/) is a website visited by thousands of UBC students for getting into classes but also for viewing the grades analyzer. Retrieving grades from UBC Pair is cumbersome. It's interesting to note that one of my classes last semester, CPSC 310, encountered the same problem, and ended up just scraping the grades from Slacknotes. Slacknotes used to use external human captcha solvers via an api who will manually input them, but that costed money and was exceptionally slow.\n",
    "\n",
    "### Decisions made on the preprocessing of the data\n",
    "* Divide the captchas into 6 separate pieces, rather than training on the entire captcha\n",
    "    * Keep it as a categorization problem\n",
    "* Have to ensure that there are at least n captchas that cover all possible chars on the captchas. I hand-labelled ~90 captchas just in case and are located [in the src_captchas folder](./src_captchas)\n",
    "* CNNs aren't rotation invariant. Add rotations. I rotated the sliced character images I got and rotated it -25 to 25 degrees (step size of 1 for optimal accuracy, but for the sake of speed and showing mistakes, I made the step size 5). Characters didn't really rotate much past it. \n",
    "    * Ex.\n",
    "        * Original cropped image ![](./readme_examples/3wEYFG-3-4.jpg)\n",
    "        * Min and max rotations ![](./readme_examples/3wEYFG-3-0.jpg) ![](./readme_examples/3wEYFG-3-9.jpg)\n",
    "* crop the base image. There's no data of value on most of the image.\n",
    "    * Ex.\n",
    "        * Original ![](./src_captchas/3wEYFG.jpg)\n",
    "        * Cropped ![](./readme_examples/3wEYFG.jpg)\n",
    "\n",
    "### Things to note\n",
    "* Prefer to have at least 99.5 percent accuracy\n",
    "    * 98% accuracy on 1 character means worst case ~ 88% accuracy on 6.\n",
    "    * 96% accuracy on 1 character means worst case ~78% accuracy on 6.\n",
    "    \n",
    "### Things I learned\n",
    "* The most interesting part to me really was the processing of the data and making decisions on what my input should look like to get the best result. In class, all the data comes perfectly processed, so it was really interesting for me to try to figure out how my data should look like. Should I have put the entire captcha and make the neural network figure it out? Should I split it? Should I delete extraneous parts of the image? If I do split up all the letters, that would mean I'll have to write extra methods to make predictions of entire captchas, calculate loss, make sure that my end-to-end predictor also splits up live captchas, etc. etc. \n",
    "* I can't write a better blog post on how a CNN works than the millions that are already out there. This was a fun exercise though, I got to play around with a lot of things, but ultimately kept it as simple as possible because I didn't see a major difference if I made it much more complicated (other than it taking way longer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PreProcessor:\n",
    "    def __init__(self, source_path, whole_captchas_path, chars_path, filetype):\n",
    "        self.source_path = source_path\n",
    "        self.whole_captchas_path = whole_captchas_path\n",
    "        self.chars_path = chars_path\n",
    "        self.file_list = glob.glob(os.path.join(source_path, filetype))\n",
    "        self.char_img_width = 23\n",
    "        self.char_img_height = 40\n",
    "        \n",
    "    def preprocess(self):\n",
    "        self._reset()\n",
    "        filelist = self.file_list\n",
    "\n",
    "        for index, filepath in enumerate(filelist):\n",
    "            self.process_helper(index, filepath)\n",
    "            \n",
    "    def process_helper(self, index, filepath):\n",
    "        filename = self._get_filename(filepath)\n",
    "        image_processor = ImageProcessor(filepath, trim_width=6, trim_height=20)\n",
    "        cropped_base_img = image_processor.get_cropped_base_img()\n",
    "        chars_of_captcha = list(filename)\n",
    "        self._save_whole_captcha_img(filename, cropped_base_img)\n",
    "\n",
    "        try:\n",
    "            divided_imgs = image_processor.divide()\n",
    "            start_num = 0\n",
    "            for index_in_captcha, piece in enumerate(divided_imgs, start_num):\n",
    "                current_char = self._format_if_upper(chars_of_captcha[index_in_captcha])\n",
    "                char_img = image_processor.get_char_img(piece)\n",
    "                \n",
    "                self._mkdir(self.chars_path + current_char)\n",
    "                self._save_char_img_within_whole_captcha(filename, current_char, char_img)\n",
    "                rotated_imgs = image_processor.rotate_divided_imgs(char_img)\n",
    "                for j, rotated_img in enumerate(rotated_imgs):\n",
    "                    self._save_rotated_img(rotated_img, current_char, filename, index_in_captcha, j)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    # Process images into a matrix. X is a w x h x 3 matrix which represents every single\n",
    "    # pixel in the image. y represents the image's character\n",
    "    def process_char_imgs_into_matrix(self):\n",
    "        dir_chars = glob.glob(os.path.join(self.chars_path, '*'))\n",
    "        char_index_dict = {k: v for v, k in enumerate(os.listdir(self.chars_path)[:])}\n",
    "\n",
    "        n = self._get_num_files(self.chars_path)\n",
    "        X = np.empty((n, self.char_img_width, self.char_img_height, 3), dtype='uint8')\n",
    "        y = np.empty((n,1), dtype='uint8')\n",
    "        \n",
    "        count = 0\n",
    "        i = 0\n",
    "        \n",
    "        for dir_char in dir_chars:\n",
    "            char = self._get_filename(dir_char)\n",
    "            filelist = glob.glob(os.path.join(self.chars_path + char,\"*.jpg\"))\n",
    "            count += len(filelist)\n",
    "            for filenum, file in enumerate(filelist):\n",
    "                char_img = imageio.imread(file).reshape(self.char_img_width, self.char_img_height, 3)\n",
    "                X[i] = char_img\n",
    "                y[i] = char_index_dict[char]\n",
    "                i += 1\n",
    "                \n",
    "        # Turn y into categorical classes\n",
    "        d = len(dir_chars)\n",
    "        y = keras.utils.to_categorical(y, d)\n",
    "\n",
    "        return X,y\n",
    "    \n",
    "        \n",
    "    # Save rotated image within character folder\n",
    "    def _save_rotated_img(self, rotated_img, current_char, filename, index_in_captcha, j):\n",
    "        path = os.path.join(chars_path + \"/%s/%s-%d-%d.jpg\" % (current_char, filename, index_in_captcha, j))\n",
    "        rotated_img.save(path)\n",
    "    \n",
    "    # Save the whole captcha image in the whole captchas folder\n",
    "    def _save_whole_captcha_img(self, filename, cropped_base_img):\n",
    "        whole_captcha_path = os.path.join(self.whole_captchas_path + filename)\n",
    "        self._mkdir(whole_captcha_path)\n",
    "        whole_captcha_img_path = os.path.join(whole_captcha_path + \"/%s\" % (filename + \".jpg\"))\n",
    "        cropped_base_img.save(whole_captcha_img_path)\n",
    "    \n",
    "    # Save individual character image within whole captcha path\n",
    "    def _save_char_img_within_whole_captcha(self, filename, current_char, char_img):\n",
    "        character_within_whole_captcha_path = os.path.join(self.whole_captchas_path + \"%s/%s.jpg\" % (filename, current_char))\n",
    "        char_img.save(character_within_whole_captcha_path)\n",
    "\n",
    "    # Delete all files in the destination paths\n",
    "    def _reset(self):\n",
    "        shutil.rmtree(self.chars_path)\n",
    "        shutil.rmtree(self.whole_captchas_path)\n",
    "        os.mkdir(self.chars_path)\n",
    "        os.mkdir(self.whole_captchas_path)\n",
    "    \n",
    "    # Create a directory if it does not exists\n",
    "    def _mkdir(self, path):\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "    \n",
    "    # Get only the filename given a path\n",
    "    def _get_filename(self, path):\n",
    "        return path.rsplit(\"/\",1)[-1].split(\".\")[0]\n",
    "    \n",
    "    # Get the number of files within the directory given\n",
    "    def _get_num_files(self, path):\n",
    "        total = 0\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            total += len(files)\n",
    "        return total\n",
    "    \n",
    "    def _format_if_upper(self, char):\n",
    "        if char.isupper():\n",
    "            return \"cap-\" + char\n",
    "        return char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    def __init__(self, path, trim_width, trim_height):\n",
    "        self.img = Image.open(path)\n",
    "        self.width = (self.img.size[0] - trim_width * 2) // trim_width\n",
    "        self.height = (self.img.size[1] - trim_height * 2)\n",
    "        self.trim_width = trim_width\n",
    "        self.trim_height = trim_height\n",
    "        \n",
    "    def get_char_width(self):\n",
    "        return self.width\n",
    "    \n",
    "    def get_char_height(self):\n",
    "        return self.height\n",
    "        \n",
    "    # Get entire captcha\n",
    "    def get_char_img(self, char_piece):\n",
    "        img = Image.new('RGB', (self.width, self.height), 255)\n",
    "        img.paste(char_piece)\n",
    "        return img\n",
    "        \n",
    "    # Rotate images to provide more data\n",
    "    def rotate_divided_imgs(self, char_img):\n",
    "        #rotation step-size is very large (5)\n",
    "        for angle in range(-25, 25, 5):\n",
    "            yield self.get_rotated_img(char_img, angle)\n",
    "            \n",
    "    # Given an angle, rotate image by that much. Must do this or the trained model won't train on rotations well.\n",
    "    def get_rotated_img(self, char_img, angle):\n",
    "        new_img = Image.new(\"RGBA\", (int(self.width),int(self.height)), \"red\")\n",
    "        background_red_img = Image.new(\"RGBA\", (self.width,self.height), \"red\")\n",
    "        src_img = char_img.convert('RGBA')\n",
    "        rotated_img = src_img.rotate(angle)\n",
    "        new_img.paste( rotated_img, (0,0), rotated_img)\n",
    "        new_img = new_img.convert(\"RGB\")\n",
    "        return new_img\n",
    "    \n",
    "    # Crop original image to not cause divisions that trim too much\n",
    "    def get_cropped_base_img(self):\n",
    "        width, height = self.img.size\n",
    "        box = (self.trim_width, self.trim_height, width - self.trim_width, height - self.trim_height)\n",
    "        cropped_img = self.img.crop(box)\n",
    "        return cropped_img\n",
    "    \n",
    "    # Divide Image into 6 parts\n",
    "    def divide(self):\n",
    "        cropped_img = self.get_cropped_base_img()\n",
    "        imgwidth, imgheight = cropped_img.size\n",
    "        for i in range(int(imgheight)//int(self.height)):\n",
    "            for j in range(int(imgwidth)//int(self.width)):\n",
    "                box = (j*self.width, i*self.height, (j+1)*self.width, (i+1)*self.height)\n",
    "                yield cropped_img.crop(box)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#super simple cnn no fancy schmancy anything\n",
    "class ConvolutionalNeuralNetwork:\n",
    "    def __init__(self, chars_path, batch_size, epochs):\n",
    "        self.chars_path = chars_path\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.num_classes = len(glob.glob(os.path.join(chars_path, '*')))\n",
    "        self.model = Sequential()\n",
    "        self.mistakes = None\n",
    "        self.history = None\n",
    "    \n",
    "    def fit(self, Xtrain, ytrain):\n",
    "        Xtrain = Xtrain.astype('float32') #tf requires float32, no uint no float64\n",
    "        Xtrain /= 255 \n",
    "        \n",
    "        model = self.model\n",
    "        \n",
    "        model.add(Conv2D(32, (3, 3), padding='same', input_shape=Xtrain.shape[1:]))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(self.num_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(Xtrain, ytrain,validation_split=0.33, batch_size=self.batch_size, epochs=self.epochs, verbose=1)\n",
    "        self.history = history\n",
    "        self.model = model\n",
    "        \n",
    "    def get_history(self):\n",
    "        if self.history is None:\n",
    "            raise Exception('Must run the fit function before getting the history!')\n",
    "            \n",
    "        return self.history\n",
    "\n",
    "        \n",
    "    def get_model(self):\n",
    "        if self.model is None:\n",
    "            raise Exception('Must run the fit function before getting the history!')\n",
    "            \n",
    "        return self.model\n",
    "        \n",
    "    def get_summary(self):\n",
    "        return self.model.summary()\n",
    "    \n",
    "    def predict(self, Xtest, ytest):\n",
    "        Xtest = Xtest.astype('float32')\n",
    "        Xtest /= 255\n",
    "        scores = self.model.evaluate(Xtest, ytest, verbose=1)\n",
    "        print('Test loss :', scores[0])\n",
    "        print('Test accuracy:', scores[1])\n",
    "    \n",
    "    def predict_all_whole_captchas(self, src_captchas_path):\n",
    "        dir_whole_captchas = os.listdir(src_captchas_path)[1:]\n",
    "        char_val_dict = {k: v for v, k in enumerate(os.listdir(self.chars_path)[:])}\n",
    "        val_chars_dict = {v: k for v, k in enumerate(list(filter(lambda x:   x.endswith(\".DS_Store\") == False, os.listdir(self.chars_path)[:])))}\n",
    "        \n",
    "        n = len(dir_whole_captchas)\n",
    "        y = np.zeros((n,6,1), dtype='uint8')\n",
    "        y_preds = np.zeros((n,6,1), dtype='uint8')\n",
    "        \n",
    "        for i, filename in enumerate(dir_whole_captchas):\n",
    "            path = os.path.join(os.path.join(src_captchas_path, filename))\n",
    "            image_processor = ImageProcessor(path, 6, 20)\n",
    "            char_list = list(filename)\n",
    "            divided_imgs = image_processor.divide()\n",
    "            preds = []\n",
    "            \n",
    "            for k, piece in enumerate(divided_imgs):\n",
    "                current_char = self._format_if_upper(char_list[k])\n",
    "                \n",
    "                img = image_processor.get_char_img(piece)\n",
    "                \n",
    "                X = np.empty((1, 23, 40,3), dtype='uint8')\n",
    "                \n",
    "                y[i][k] = char_val_dict[current_char]\n",
    "                \n",
    "                X[0] = np.array(img).reshape(23,40,3)\n",
    "\n",
    "                probs_pred = self.model.predict(X)\n",
    "                pred = val_chars_dict[np.argmax(probs_pred)]\n",
    "                preds.append(pred[-1])\n",
    "                \n",
    "                y_preds[i][k] = char_val_dict[pred]\n",
    "                \n",
    "        accuracy = (y == y_preds).all(-2).sum() / len(y)\n",
    "        loss = 1 - accuracy\n",
    "\n",
    "        not_equal = (y != y_preds).all(2)\n",
    "        \n",
    "        wrong_preds = y_preds[np.where(not_equal)[0]]\n",
    "        actual = y[np.where(not_equal)[0]]\n",
    "        self._store_mistakes_from_whole_captchas(actual, wrong_preds)\n",
    "        \n",
    "        print('Whole Captcha Test loss:', loss)\n",
    "        print('Whole Captcha Test accuracy:', accuracy)\n",
    "        return accuracy, loss\n",
    "    \n",
    "    def make_prediction_from_whole_captchas(self, path):\n",
    "        val_chars_dict = {v: k for v, k in enumerate(list(filter(lambda x:   x.endswith(\".DS_Store\") == False, os.listdir(self.chars_path)[:])))}\n",
    "        image_processor = ImageProcessor(path, 6, 20)\n",
    "        divided_imgs = image_processor.divide()\n",
    "        preds = []\n",
    "        for k,piece in enumerate(divided_imgs):\n",
    "            img = image_processor.get_char_img(piece)\n",
    "            \n",
    "            X = np.empty((1, 23, 40,3), dtype='uint8')\n",
    "            X[0] = np.array(img).reshape(23,40,3)\n",
    "\n",
    "            probs_pred = self.model.predict(X)\n",
    "            pred = val_chars_dict[np.argmax(probs_pred)]\n",
    "            preds.append(pred[-1])\n",
    "        return \"\".join(preds)\n",
    "    \n",
    "    def get_mistakes(self):\n",
    "        if self.mistakes is None:\n",
    "            raise Exception('Must run the predict function first before finding out which predictions you got wrong!')\n",
    "\n",
    "        self._transform_mistakes()\n",
    "    \n",
    "    def _transform_mistakes(self):\n",
    "        actual, wrong_preds = self.mistakes\n",
    "        char_val_dict = {k: v for v, k in enumerate(os.listdir(self.chars_path)[:])}\n",
    "        keys = char_val_dict.keys()\n",
    "        list_keys = list(keys)\n",
    "        for key in keys:\n",
    "            if \"cap\" in key:\n",
    "                j = char_val_dict[key]\n",
    "                list_keys[j] = key[-1]\n",
    "        keys = np.array(list_keys)\n",
    "        \n",
    "        for i in range(len(wrong_preds)):\n",
    "            flattened_pred = \"\".join(keys[np.ndarray.flatten(wrong_preds[i])])\n",
    "            flattened_actual = \"\".join(keys[np.ndarray.flatten(actual[i])])\n",
    "            print(\"Actual: %s   -   Pred: %s\" % (flattened_actual, flattened_pred))\n",
    "    \n",
    "    def _store_mistakes_from_whole_captchas(self, actual, wrong_preds):\n",
    "        self.mistakes = (actual, wrong_preds)\n",
    "    \n",
    "    def _format_if_upper(self, char):\n",
    "        if char.isupper():\n",
    "            return \"cap-\" + char\n",
    "        return char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processor = PreProcessor(source_path, whole_captchas_path, chars_path, filetype)\n",
    "processor.preprocess()\n",
    "X, y = processor.process_char_imgs_into_matrix()\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the sake of speed, and showing mistakes, I made the iteration step size of the rotations in the \n",
    "# ImageProcessor 5. \n",
    "# if you want better accuracy lower the iteration step size of the rotations and/or increase number of epochs\n",
    "# it'll take longer to preprocess and fit the data though.\n",
    "# My best and most consistant performance of getting 0 wrong on the test set and solving almost all of the \n",
    "# new live catpchas was with a rotation step size of 1, and at least 15 epochs.\n",
    "cnn = ConvolutionalNeuralNetwork(chars_path, batch_size=32, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2342 samples, validate on 1155 samples\n",
      "Epoch 1/15\n",
      "2342/2342 [==============================] - 2s 924us/step - loss: 3.1597 - acc: 0.2451 - val_loss: 2.1373 - val_acc: 0.3957\n",
      "Epoch 2/15\n",
      "2342/2342 [==============================] - 2s 723us/step - loss: 1.3302 - acc: 0.6712 - val_loss: 1.1980 - val_acc: 0.6364\n",
      "Epoch 3/15\n",
      "2342/2342 [==============================] - 2s 815us/step - loss: 0.6528 - acc: 0.8224 - val_loss: 0.7741 - val_acc: 0.7766\n",
      "Epoch 4/15\n",
      "2342/2342 [==============================] - 2s 874us/step - loss: 0.4008 - acc: 0.8830 - val_loss: 0.5746 - val_acc: 0.8390\n",
      "Epoch 5/15\n",
      "2342/2342 [==============================] - 2s 812us/step - loss: 0.2738 - acc: 0.9304 - val_loss: 0.4508 - val_acc: 0.8788\n",
      "Epoch 6/15\n",
      "2342/2342 [==============================] - 2s 867us/step - loss: 0.1911 - acc: 0.9492 - val_loss: 0.4544 - val_acc: 0.8658\n",
      "Epoch 7/15\n",
      "2342/2342 [==============================] - 2s 789us/step - loss: 0.1506 - acc: 0.9552 - val_loss: 0.3875 - val_acc: 0.8961\n",
      "Epoch 8/15\n",
      "2342/2342 [==============================] - 2s 870us/step - loss: 0.1108 - acc: 0.9735 - val_loss: 0.3391 - val_acc: 0.9056\n",
      "Epoch 9/15\n",
      "2342/2342 [==============================] - 2s 748us/step - loss: 0.0838 - acc: 0.9761 - val_loss: 0.3967 - val_acc: 0.8926\n",
      "Epoch 10/15\n",
      "2342/2342 [==============================] - 2s 735us/step - loss: 0.0635 - acc: 0.9808 - val_loss: 0.3597 - val_acc: 0.9004\n",
      "Epoch 11/15\n",
      "2342/2342 [==============================] - 2s 800us/step - loss: 0.0522 - acc: 0.9868 - val_loss: 0.3189 - val_acc: 0.9169\n",
      "Epoch 12/15\n",
      "2342/2342 [==============================] - 2s 791us/step - loss: 0.0388 - acc: 0.9893 - val_loss: 0.3801 - val_acc: 0.9065\n",
      "Epoch 13/15\n",
      "2342/2342 [==============================] - 2s 762us/step - loss: 0.0333 - acc: 0.9923 - val_loss: 0.3425 - val_acc: 0.9082\n",
      "Epoch 14/15\n",
      "2342/2342 [==============================] - 2s 735us/step - loss: 0.0264 - acc: 0.9932 - val_loss: 0.3210 - val_acc: 0.9169\n",
      "Epoch 15/15\n",
      "2342/2342 [==============================] - 2s 729us/step - loss: 0.0281 - acc: 0.9919 - val_loss: 0.2976 - val_acc: 0.9247\n"
     ]
    }
   ],
   "source": [
    "cnn.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1723/1723 [==============================] - 0s 208us/step\n",
      "Test loss : 0.27416828380237124\n",
      "Test accuracy: 0.9257109693434787\n"
     ]
    }
   ],
   "source": [
    "cnn.predict(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7e5wTG'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.make_prediction_from_whole_captchas(source_path + \"7e5wTG.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole Captcha Test loss: 0.05747126436781613\n",
      "Whole Captcha Test accuracy: 0.9425287356321839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9425287356321839, 0.05747126436781613)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.predict_all_whole_captchas(source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 6EJrPp   -   Pred: 6FJrPp\n",
      "Actual: cTaRVd   -   Pred: rTaRVd\n",
      "Actual: QCsCK3   -   Pred: QCsCKT\n",
      "Actual: RxeXf4   -   Pred: RxeXY4\n",
      "Actual: Vce8JC   -   Pred: Hce8JC\n"
     ]
    }
   ],
   "source": [
    "#note this is out of ~90 captchas\n",
    "cnn.get_mistakes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
